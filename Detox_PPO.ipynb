{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚¨áÔ∏è Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer,\n",
    "    RobertaForSequenceClassification,   # reward model\n",
    "    RobertaTokenizer,                   # reward model tokenizer\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from trl import (\n",
    "    AutoModelForCausalLMWithValueHead, \n",
    "    PPOConfig, \n",
    "    PPOTrainer,\n",
    "    create_reference_model,\n",
    "    set_seed,\n",
    ")\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'ybelkada/gpt-j-6b-sharded-bf16'\n",
    "model_name = 'EleutherAI/gpt-neo-125m'      # smallest one\n",
    "log_with = None                     # or 'wandb'\n",
    "learning_rate = (1.47e-5) * 2       # default one (?)\n",
    "mini_batch_size = 4                 # PPO minibatch size\n",
    "batch_size = 14                     # batchsize (for the model?)\n",
    "ppo_epochs = 100\n",
    "gradient_accumulation_steps = 1     # [TODO]: check what is this!\n",
    "model_save_path = './checkpoints/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name = model_name,\n",
    "    learning_rate = learning_rate,\n",
    "    log_with = log_with,\n",
    "    ppo_epochs = ppo_epochs,\n",
    "    mini_batch_size = mini_batch_size,\n",
    "    batch_size = batch_size,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Method that loads the dataset, customize it to train on different data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/daniel/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-eb8779dd2693db47/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n",
      "Loading cached processed dataset at /Users/daniel/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-eb8779dd2693db47/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-e598224e6b946c4a.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db16945b89a45de96fce45496a9d434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35109 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_dataset(\n",
    "    config, \n",
    "    dataset_name=\"allenai/real-toxicity-prompts\", \n",
    "    input_min_text_length=10, \n",
    "    input_max_text_length=15,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset` and returns \n",
    "    a Dataloader class (from torch.utils.data)\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded. (from load_dataset)\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    # from the PPO trainer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    ds = load_dataset(dataset_name, split = \"train\")\n",
    "\n",
    "    # function to filter only prompts that lead to a toxicity score > 0.3\n",
    "    # in order to increase the chances for the model to generate toxicity prompts\n",
    "    def filter_fn(sample):\n",
    "        toxicity = sample[\"prompt\"][\"toxicity\"]\n",
    "        return toxicity is not None and toxicity > 0.3\n",
    "\n",
    "    ds = ds.filter(filter_fn, batched=False)\n",
    "    \n",
    "    # only prompts in between input_min_text_length : input_max_text_length\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        prompt = sample[\"prompt\"][\"text\"]\n",
    "        continuation = sample[\"continuation\"][\"text\"]\n",
    "\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt + continuation)[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # tokenize\n",
    "    ds = ds.map(tokenize, batched = False)\n",
    "    # set as torch.utils.data.DataLoader\n",
    "    ds.set_format(type=\"torch\")\n",
    "\n",
    "    ds = ds.train_test_split(test_size = 0.2, shuffle = False)[\"train\"]\n",
    "\n",
    "    return ds\n",
    "\n",
    "# Getting dataset\n",
    "min_input_length = 30\n",
    "max_input_length = 40\n",
    "dataset = build_dataset(\n",
    "    config, \n",
    "    input_min_text_length = min_input_length, \n",
    "    input_max_text_length = max_input_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other stuff\n",
    "\n",
    "# set seed before initializing value head for deterministic eval\n",
    "set_seed(config.seed)\n",
    "\n",
    "# dunno\n",
    "def collator(data):\n",
    "    return dict(\n",
    "        (key, [d[key] for d in data]) for key in data[0]\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference model\n",
    "We load the model in bfloat16 to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m ref_model \u001b[39m=\u001b[39m create_reference_model(\n\u001b[1;32m      8\u001b[0m     model, \n\u001b[1;32m      9\u001b[0m     num_shared_layers \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m,\n\u001b[1;32m     10\u001b[0m     pattern \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtransformer.h.\u001b[39m\u001b[39m{layer}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m# We make sure to use `Adam` optimizer on the model parameters that require gradients.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m optimizer \u001b[39m=\u001b[39m Adam(\n\u001b[1;32m     14\u001b[0m     \u001b[39mfilter\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m p: p\u001b[39m.\u001b[39;49mrequires_grad, model\u001b[39m.\u001b[39;49mparameters()), \n\u001b[1;32m     15\u001b[0m     lr \u001b[39m=\u001b[39;49m config\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_new/lib/python3.9/site-packages/torch/optim/adam.py:33\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid weight_decay value: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(weight_decay))\n\u001b[1;32m     29\u001b[0m defaults \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(lr\u001b[39m=\u001b[39mlr, betas\u001b[39m=\u001b[39mbetas, eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m     30\u001b[0m                 weight_decay\u001b[39m=\u001b[39mweight_decay, amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[1;32m     31\u001b[0m                 maximize\u001b[39m=\u001b[39mmaximize, foreach\u001b[39m=\u001b[39mforeach, capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[1;32m     32\u001b[0m                 differentiable\u001b[39m=\u001b[39mdifferentiable, fused\u001b[39m=\u001b[39mfused)\n\u001b[0;32m---> 33\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m fused:\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_new/lib/python3.9/site-packages/torch/optim/optimizer.py:187\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    185\u001b[0m param_groups \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(params)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(param_groups) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39moptimizer got an empty parameter list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(param_groups[\u001b[39m0\u001b[39m], \u001b[39mdict\u001b[39m):\n\u001b[1;32m    189\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "# model loaded in float16 to reduce memory usage\n",
    "model = AutoModelForCausalLM.from_pretrained(config.model_name, torch_dtype = torch.bfloat16)\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(model)\n",
    "\n",
    "# GPT-2 / GPT-J tokenizer has a pad token, but it is not eos_token by default. We need to set it to eos_token.\n",
    "# only for this model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "## so ONLY FOR GPT (?)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# reference model sharing 20 layers\n",
    "# reference models are frozen copies of the model that is trained (in eval mode) [from doc]\n",
    "ref_model = create_reference_model(\n",
    "    model, \n",
    "    num_shared_layers = 20,\n",
    "    pattern = 'transformer.h.{layer}'\n",
    ")\n",
    "\n",
    "# We make sure to use `Adam` optimizer on the model parameters that require gradients.\n",
    "optimizer = Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr = config.learning_rate,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debug session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-11): 12 x GPTNeoBlock(\n",
       "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): GPTNeoAttention(\n",
       "      (attention): GPTNeoSelfAttention(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): GPTNeoMLP(\n",
       "      (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (act): NewGELUActivation()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_model.transformer.h[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer pattern could not be matched.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_reference_model(model\u001b[39m.\u001b[39;49mpretrained_model\u001b[39m.\u001b[39;49mtransformer\u001b[39m.\u001b[39;49mh, num_shared_layers \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_new/lib/python3.9/site-packages/trl/models/modeling_base.py:309\u001b[0m, in \u001b[0;36mcreate_reference_model\u001b[0;34m(model, num_shared_layers, pattern)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m pattern \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLayer pattern could not be matched.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[39m# divide parameters in shared and unshared parameter lists\u001b[39;00m\n\u001b[1;32m    312\u001b[0m shared_param_list \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Layer pattern could not be matched."
     ]
    }
   ],
   "source": [
    "create_reference_model(model.pretrained_model.transformer.h, num_shared_layers = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformer.h.20'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = 'transformer.h.{layer}'\n",
    "pattern.format(layer = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m ppo_trainer \u001b[39m=\u001b[39m PPOTrainer(\n\u001b[1;32m      2\u001b[0m     config,\n\u001b[1;32m      3\u001b[0m     model,\n\u001b[1;32m      4\u001b[0m     ref_model\u001b[39m=\u001b[39mref_model,\n\u001b[1;32m      5\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[1;32m      6\u001b[0m     dataset\u001b[39m=\u001b[39mdataset,\n\u001b[1;32m      7\u001b[0m     data_collator\u001b[39m=\u001b[39mcollator,\n\u001b[0;32m----> 8\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(\n",
    "    config,\n",
    "    model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset,\n",
    "    data_collator=collator,\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f95e20241bd49a88ced9b29e6af4fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'ppo_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m toxicity_tokenizer \u001b[39m=\u001b[39m RobertaTokenizer\u001b[39m.\u001b[39mfrom_pretrained(toxicity_model_id)\n\u001b[1;32m      3\u001b[0m \u001b[39m# Also load the toxicity model in fp16 to save memory\u001b[39;00m\n\u001b[1;32m      4\u001b[0m toxicity_model \u001b[39m=\u001b[39m RobertaForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      5\u001b[0m     toxicity_model_id, \n\u001b[1;32m      6\u001b[0m     torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16\n\u001b[0;32m----> 7\u001b[0m )\u001b[39m.\u001b[39mto(ppo_trainer\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ppo_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "toxicity_model_id = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = RobertaTokenizer.from_pretrained(toxicity_model_id)\n",
    "# Also load the toxicity model in fp16 to save memory\n",
    "toxicity_model = RobertaForSequenceClassification.from_pretrained(\n",
    "    toxicity_model_id, \n",
    "    torch_dtype=torch.float16\n",
    ").to(ppo_trainer.accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then define the arguments to pass to the `generate` function. These arguments\n",
    "# are passed to the `generate` function of the PPOTrainer, which is a wrapper around\n",
    "# the `generate` function of the trained model.\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}\n",
    "output_min_length = 20\n",
    "output_max_length = 30\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from the policy model\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    # Compute sentiment score # noqa\n",
    "    texts = batch[\"response\"]\n",
    "    toxicity_inputs = toxicity_tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(\n",
    "        ppo_trainer.accelerator.device\n",
    "    )\n",
    "    logits = toxicity_model(**toxicity_inputs).logits.float()\n",
    "    toxicity_labels = (logits[:, 0]).tolist()\n",
    "\n",
    "    rewards = [torch.tensor(output) for output in toxicity_labels]\n",
    "\n",
    "    # Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "    # Save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        if ppo_trainer.accelerator.is_main_process:\n",
    "            ppo_trainer.save_pretrained(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
