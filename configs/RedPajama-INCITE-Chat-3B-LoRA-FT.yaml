# togethercomputer/RedPajama-INCITE-Chat-3B-v1

model_id: DanielSc4/RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1
debug: yes
load_from_peft: yes
inference_batch_size: 32
model_label: 'FT'   # fine-tuned

generation:
  custom_prompt:
    # from original togethercomputer doc
    user_name: '<human>:'
    bot_name: '<bot>:'
  generation_config:
    max_new_tokens: 70
    min_new_tokens: 4
    do_sample: yes
    temperature: 0.7
    top_p: 0.8
    top_k: 50
    no_repeat_ngram_size: 2

RL_args:
  reward_model_id: facebook/roberta-hate-speech-dynabench-r4-target
  PPO_config:
    learning_rate: 0.000005
    log_with: wandb        # CHANGE w/ wandb
    mini_batch_size: 8    # (16) mini batch size (<= batch size) for each model forward pass 
    batch_size: 64        # (256) batch size used for each optimization step
    gradient_accumulation_steps: 2

LoRA_config:
  r: 64                   # the rank of the update matrices. Lower -> fewer trainable params
  lora_alpha: 32          # LoRA scaling factor
  target_modules:
    - "query_key_value"   # (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
  lora_dropout: 0.05      # 
  bias: 'none'            # if the bias parameters should be trained ['none', 'lora_only', 'all']
  task_type: 'CAUSAL_LM'  # task

fine_tune_args:
  per_device_eval_batch_size: 32
  per_device_eval_batch_size: 4
  eval_accumulation_steps: 5
  gradient_accumulation_steps: 2
  warmup_steps: 100
  num_train_epochs: 4
  learning_rate: 0.0003
  optim: 'adamw_torch'
  save_strategy: "steps"
  save_steps: 200
  auto_find_batch_size: yes
  use_mps_device: no
  logging_strategy: 'steps'
  logging_steps: 10
  save_total_limit: 4
  report_to: wandb
  push_to_hub: yes        # new_ test push to hub while training

data:
  subset: no   # Used for debug. If no, the following will be ignored
  subset_size: 30
