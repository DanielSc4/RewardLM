{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## dependencies for colab\n",
    "# !git clone https://__TOKEN_GIT__:@github.com/DanielSc4/RL-on-LM.git\n",
    "# %cd RL-on-LM/\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ðŸ—½ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rewardlm.data.data_utils import download_DIALOCONAN\n",
    "from rewardlm.ToxicityMeter import ToxicityMeter\n",
    "from transformers import GenerationConfig\n",
    "from rewardlm.utils.general_utils import device_selector\n",
    "\n",
    "# from rewardlm.data.data_utils import gen_benchmark_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = 'EleutherAI/gpt-neo-125m'\n",
    "model_id = 'EleutherAI/pythia-70m'      # prototype model\n",
    "# model_id = 'EleutherAI/pythia-2.8b'\n",
    "# model_id = 'MBZUAI/LaMini-GPT-124M'\n",
    "# model_id = 'MBZUAI/LaMini-GPT-774M'\n",
    "# model_id = 'MBZUAI/LaMini-GPT-1.5B'\n",
    "# model_id = 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1'\n",
    "model_ids = [\n",
    "    'MBZUAI/LaMini-GPT-124M',\n",
    "    'MBZUAI/LaMini-GPT-774M',\n",
    "    'MBZUAI/LaMini-GPT-1.5B',\n",
    "    'togethercomputer/RedPajama-INCITE-Instruct-3B-v1',\n",
    "    'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
    "    'bigscience/bloomz-1b7',    # 1.7 billion\n",
    "    'bigscience/bloomz-3b',     # 3 billion\n",
    "    'bigscience/bloomz-7b1',    # 7.1 billion\n",
    "\n",
    "]\n",
    "\n",
    "reward_model_id = 'facebook/roberta-hate-speech-dynabench-r4-target'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Temporary management of the dataset:\n",
    "# Decided to focus only on the firts 2 turns of the dialog.\n",
    "# The prompt will be the toxic text reported in the dataset and the model \n",
    "# should produce a non-toxic response; \n",
    "# eventually, the model, will be instructed trough RL\n",
    "# in debunking the initial statement\n",
    "\n",
    "# selecting only the first text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = download_DIALOCONAN()\n",
    "query = dataset['turn_id'] == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.24s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.82s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.14s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_id in model_ids:\n",
    "    print(f'Testing {model_id}')\n",
    "    \n",
    "    load_dtype = 'bf16' # can be ['8-bit', 'bf16',]\n",
    "    toxicity_meter = ToxicityMeter(\n",
    "        model_id = model_id,\n",
    "        load_dtype = load_dtype, # can be ['8-bit', 'bf16',]\n",
    "        toxicity_model_id = reward_model_id,\n",
    "        device = device_selector(),\n",
    "    )\n",
    "\n",
    "    custom_prompt = ('Statement: \"{prompt}\".\\nResponse: ')\n",
    "    # custom prompts required by papers\n",
    "    if model_id == 'togethercomputer/RedPajama-INCITE-Chat-3B-v1':\n",
    "        custom_prompt = ('<human>: \"{prompt}\"\\n<bot>: ')\n",
    "    \n",
    "\n",
    "    # samples: 25, top-p: 0.9, temperature = 1, max_len = 20\n",
    "    generation_config = GenerationConfig(\n",
    "        max_new_tokens = 25,\n",
    "        num_beams = 5,\n",
    "        early_stopping = True,\n",
    "        pad_token_id = 0,       # crashes while using batchsize > 1 only on mps device if not set\n",
    "        temperature = 0.8,\n",
    "        top_p = .8,\n",
    "        # diversity_penalty = .1, # should use num_beam_groups > 1\n",
    "    )\n",
    "\n",
    "\n",
    "    toxicity_df = toxicity_meter.measure_toxicity(\n",
    "        text_prompt = dataset[query]['text'].to_list()[:30],   # REMOVE [:100], just for testing purpose\n",
    "        custom_prompt = custom_prompt, \n",
    "        generation_config = generation_config,\n",
    "        batch_size = 16,\n",
    "    )\n",
    "\n",
    "    # save csv in tmp folder\n",
    "    toxicity_df.to_csv(f'./result analysis/tmp/measured_tox_instruct_{model_id.split(\"/\")[-1]}_{load_dtype}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_df.to_csv(f'../measured_toxicity_{model_id.split(\"/\")[-1]}_{load_dtype}_(2)_normal_prompt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
